_athena: &athena
  type: iris.extras.datasets.athena_dataset.AthenaQueryDataSet
  region: ${region}
  database: ${database_name}
  bucket: ${bucket_name}
  athena_path: ${athena_output_prefix}

_parquet_spark: &parquet
  type: spark.SparkDataSet
  file_format: parquet
  load_args: &parquet_load_args
    header: True
    inferSchema: True
  save_args: &parquet_save_args
    sep: '|'
    header: True
    mode: overwrite
    maxRecordsPerFile: 1000

transactions:
  <<: *athena
  query: |
    SELECT *, year(cast(date as timestamp)) as year, month(cast(date as timestamp)) as month
    FROM "${database_name}".transactions
    LIMIT 5000
  partition_cols: [year, month]

parsed:
  <<: *parquet
  filepath: s3a://${bucket_name}/${nightly_prefix}/parsed/
  save_args:
    <<: *parquet_save_args
    partitionBy: ${partitions.parsed}

iris:
  type: pandas.CSVDataSet
  filepath: data/iris.csv

dummy:
  type: pandas.CSVDataSet
  filepath: data/iris.csv

dummy_out:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/out
  versioned: true

model:
  type: pickle.PickleDataSet
  backend: pickle  # or joblib
  filepath: data/06_models/model
  versioned: True

# transcode the versioned model artifacts into partitioned dataset
# in order to access different versions at once
models:
  type: PartitionedDataSet
  path: data/06_models/model
  dataset:
    type: pickle.PickleDataSet
    backend: pickle

model_package_arn:
  type: json.JSONDataSet
  filepath: data/06_models/model_package_arn.json
  versioned: True

model_arn:
  type: json.JSONDataSet
  filepath: data/06_models/model_arn.json
  versioned: True
